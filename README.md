# Overview

The script `rlhf_activation_patching.py` was mostly generated by Claude Sonnet 4.5 and trains a single epoch using 1000 prompts from the helpful/harmful dataset. This does not seem to be enough to qualatively change the output, but it's enough to give a pretty plot `layer_importance.py`, showing that later layers are more affected by human-preference finetuning using DPO.
